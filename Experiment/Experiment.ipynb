{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium_stealth import stealth\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pyyoutube\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import pafy\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from tqdm import notebook\n",
    "from IPython.display import clear_output\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hide video unavailable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"AIzaSyBHonuF98PzbYOg7Z1ZFnlAaHjl0Gh3Kjg\",  \n",
    "        \"AIzaSyDvaaNTMomMcvGwcz-TrvdrgTlvk4TDAeg\", \n",
    "        \"AIzaSyDvD8rnCKonVOnWAtZCfAu22svlgY9dsuU\",\n",
    "        \"AIzaSyA1tCsmnGtTrNLDW_SKyWkArihc3o-bCho\",\n",
    "        \"AIzaSyDvk4LR8GYYEMtuKwCQWcVWgaBnY2ftW8A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = pyyoutube.Api(api_key=keys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_key(api, key_list):\n",
    "    current = key_list.index(api._api_key)\n",
    "    print(\"Updating API key...\")\n",
    "    \n",
    "    while current < len(key_list):\n",
    "        api = pyyoutube.Api(api_key=key_list[current])\n",
    "        \n",
    "        try: # see if this key is functional\n",
    "            api.get_channel_info(channel_id=\"UC0aanx5rpr7D1M7KCFYzrLQ\")\n",
    "            return api\n",
    "        except: # if it's not, try the next one\n",
    "            current += 1\n",
    "    \n",
    "    # if no key was functional, exit\n",
    "    print(\"No keys remaining...\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails = pd.read_csv(\"../data/mails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = pd.read_csv(\"../data/uploads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = pd.read_csv(\"../data/training_videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize words\n",
    "vectorizer = TfidfVectorizer(max_df=.75, min_df=2)\n",
    "vector = vectorizer.fit_transform(equal['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mlp = pickle.load(open('MLP_trained.sav', 'rb'))\n",
    "except:\n",
    "    # Train\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=[10]*10, activation=\"identity\",\n",
    "                        random_state=0).fit(X, Y)\n",
    "\n",
    "    # save the model to disk\n",
    "    pickle.dump(mlp, open('MLP_trained.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_duration(string):\n",
    "    \"\"\"Converts a string of time to seconds\"\"\"    \n",
    "    length = string.split(\"PT\")[1]\n",
    "    \n",
    "    length = length.replace(\"H\", \"*3600+\")\n",
    "    length = length.replace(\"M\", \"*60+\")\n",
    "    length = length.replace(\"S\", \"*1+\")\n",
    "    length += \"0\"\n",
    "    \n",
    "    return eval(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid_to_watch(videos, vectorizer, vector, equal, api, \n",
    "                 usertype = 1, experiment_part = 1, user = 0, vid_num = 0):\n",
    "    \"\"\"Finds a video to watch and makes sure \n",
    "    it's still accessible and under 2 hours long\"\"\"\n",
    "        \n",
    "    if usertype == 1 or experiment_part == 2:\n",
    "        # Choose a non-conspiracy video to watch\n",
    "        to_watch = np.random.choice(videos[~videos[\"conspiracy\"]][\"video_id\"])\n",
    "    elif usertype == 2:\n",
    "        # Choose a conspiracy video to watch\n",
    "        to_watch = np.random.choice(videos[videos[\"conspiracy\"]][\"video_id\"])\n",
    "    elif usertype == 3 or usertype == 4: # Manually checked\n",
    "        to_watch, vid_len, api = get_similar_video(user, api, equal, vector, vectorizer, vid_num)  \n",
    "    \n",
    "    if usertype < 3:\n",
    "        # Check its length\n",
    "        url = f\"http://www.youtube.com/watch?v={to_watch}\"\n",
    "        try:\n",
    "            video = pafy.new(url);\n",
    "            vid_len = video.length\n",
    "        except: # Video no longer accessible\n",
    "            vid_len = 9999\n",
    "    \n",
    "        # Videos over 1 hour will be skipped\n",
    "        while vid_len > 3600:\n",
    "            if usertype == 1 or experiment_part == 2:\n",
    "                to_watch = np.random.choice(videos[~videos[\"conspiracy\"]][\"video_id\"])\n",
    "            else:\n",
    "                to_watch = np.random.choice(videos[videos[\"conspiracy\"]][\"video_id\"])\n",
    "\n",
    "            url = f\"http://www.youtube.com/watch?v={to_watch}\"\n",
    "            try:\n",
    "                video = pafy.new(url);\n",
    "                vid_len = video.length\n",
    "            except:\n",
    "                vid_len = 9999\n",
    "            \n",
    "    # Calculate how much of the video will be watched\n",
    "    percentage = np.random.normal(0.55, 0.25)\n",
    "    \n",
    "    # Make sure a video is watched at most 100%\n",
    "    if percentage > 1:\n",
    "        percentage = 1\n",
    "    elif percentage < 0.1:\n",
    "        percentage = 0.1\n",
    "    \n",
    "    watch_time = percentage * vid_len\n",
    "    \n",
    "    # Conspiracy videos might be longer than an hour\n",
    "    # So they should be watched at max 1 hour\n",
    "    if watch_time > 3600:\n",
    "        watch_time = 3600\n",
    "\n",
    "    return watch_time, to_watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_video(user, api, equal, vector, vectorizer, vid_num):\n",
    "    \"\"\"Gets a video similar video to the one designated to this user.\"\"\"\n",
    "        \n",
    "    # Find the original video to watch\n",
    "    initial = [\"-6ZwXd44SDU\", \"X5eD5yLKUy0\", \"hl11KmzWaVg\", \"NfaqZNLcpPQ\", \"Y4lwsqG6XOg\"]\n",
    "    \n",
    "    idx = (user - 11) % 5\n",
    "    vid_id = initial[idx] \n",
    "    starting_vid = equal.query(\"video_id == @vid_id\")          \n",
    "        \n",
    "    # Find its neighbors\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "    knn.fit(vector)\n",
    "    \n",
    "    # Get the nth nearest neighbor (n = vid_num)\n",
    "    trans = vectorizer.transform(starting_vid[\"full_text\"].values)    \n",
    "    nearest = knn.kneighbors(trans, n_neighbors=5, return_distance=False)\n",
    "    vid_id = equal.iloc[nearest[0][vid_num]][\"video_id\"]\n",
    "    \n",
    "    dct=None\n",
    "    \n",
    "    # Find its duration\n",
    "    try:\n",
    "        dct = api.get_video_by_id(video_id = vid_id).items[0].to_dict()\n",
    "    except Exception as e:\n",
    "        if \"quota\" in str(e): # if the error was caused due to the quota-limit, refresh the key\n",
    "            api = update_key(api, keys)\n",
    "            dct = api.get_video_by_id(video_id = vid_id).items[0].to_dict()\n",
    "\n",
    "    # If the API returned nothing, try using pafy\n",
    "    if dct:\n",
    "        vid_len = process_duration(dct[\"contentDetails\"][\"duration\"])\n",
    "    else:\n",
    "        url = f\"http://www.youtube.com/watch?v={vid_id}\"\n",
    "        try:\n",
    "            video = pafy.new(url);\n",
    "            vid_len = video.length\n",
    "        except:\n",
    "            vid_len = 3600\n",
    "            \n",
    "    return vid_id, vid_len, api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lI8FBkp8bBo', 804, <pyyoutube.api.Api at 0x211a00ae358>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_video(17, api, equal, vector, vectorizer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_driver():\n",
    "    \"\"\"Initializes a selenium driver in stealth mode\"\"\"\n",
    "        \n",
    "    # Add options\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-blink-features\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--disable-infobars\")\n",
    "\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"--mute-audio\")\n",
    "    options.add_argument('disable-notifications')\n",
    "    # options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"user-agent='Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'\")\n",
    "    \n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    prefs = {\"credentials_enable_service\" : False, \"profile.password_manager_enabled\" : False}\n",
    "    options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "    # Start driver\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    # Hide the fact we're using a bot\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "        \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_driver().get(\"http://accounts.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_google(driver, mail, password):\n",
    "    \"\"\"Logs in on Google given a driver, email-address and password.\n",
    "    This code only works if the email-address was made within chromedriver itself\"\"\"\n",
    "    \n",
    "    # login on google\n",
    "    driver.get(\"https://accounts.google.com/ServiceLogin\")\n",
    "    time.sleep(np.random.uniform(1, 1.5))\n",
    "\n",
    "    # Fillin mail\n",
    "    driver.find_element_by_id(\"identifierId\").send_keys(mail)\n",
    "    driver.find_element_by_id(\"identifierNext\").click()\n",
    "\n",
    "    time.sleep(np.random.uniform(1, 1.5))\n",
    "\n",
    "    if driver.find_elements_by_xpath(\"//a[contains(@href, 'https://support.google.com/accounts/answer/')]\"):\n",
    "        manual = input(f\"Sign in manually for bot {mail}\")\n",
    "        if manual == \"no\":\n",
    "            return False\n",
    "    \n",
    "    # Fill in password\n",
    "    driver.find_element_by_xpath(\"//input[@name = 'password']\").send_keys(password)\n",
    "    driver.find_element_by_xpath('//button[contains(@class, \"VfPpkd-LgbsSe\")]').click()\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # If security-check is asked, skip it\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[contains(@class, 'U26fgb O0WRkf')]\").click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    driver.get(\"https://youtube.com\")\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@id = 'return-to-youtube']\").click()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//div[@class = 'VfPpkd-RLmnJb']\").click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watching the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_video(driver):\n",
    "    \"\"\"Does everything necessary to start watching a video\"\"\"\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Some videos get a warning for inappropriate content\n",
    "    content_warning = driver.find_elements_by_xpath(\n",
    "        \"//paper-button[text() = 'I understand and wish to proceed']\")\n",
    "    \n",
    "    if content_warning:\n",
    "        content_warning[0].click()\n",
    "\n",
    "    # Skip ad(s) if they are there\n",
    "    for ad in range(2):\n",
    "        time.sleep(0.5)\n",
    "        if driver.find_elements_by_xpath(\"//img[@class = 'ytp-ad-image']\"):\n",
    "            time.sleep(6)\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\"//div[@class = 'ytp-ad-text ytp-ad-skip-button-text']\").click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Toggle autoplayer\n",
    "    time.sleep(0.5)\n",
    "    try:\n",
    "        autoplay = driver.find_element_by_xpath(\"//div[@class = 'ytp-autonav-toggle-button']\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if autoplay and autoplay.get_attribute(\"aria-checked\") == \"true\":\n",
    "        autoplay.click()\n",
    "        \n",
    "    pause = driver.find_element_by_xpath(\"//button[contains(@class, 'ytp-play-button')]\")\n",
    "    \n",
    "    if pause.get_attribute(\"aria-label\") == \"Play (k)\":\n",
    "        pause.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_seconds(timestamp):\n",
    "    \"\"\"Converts a YouTube timestamp to a number of seconds\"\"\"\n",
    "    # Order times in ascending order\n",
    "    times = timestamp.split(\":\")[::-1]\n",
    "    \n",
    "    # Convert to seconds\n",
    "    return sum([int(times[i]) * 60**i for i in range(len(times))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_video_running(driver, watch_time, vid_nr, n_vids, uid):\n",
    "    \"\"\"Checks if a video is still running\"\"\"\n",
    "    # Make sure the settings are folded out so that the timestamp is visible\n",
    "    settings = driver.find_element_by_xpath(\"//button[contains(@class, 'settings')]\")\n",
    "    if not settings.get_attribute(\"aria-expanded\"):\n",
    "        try:\n",
    "            settings.click()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    timestamp = driver.find_element_by_class_name(\"ytp-time-current\").text\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"User : {uid}\\nVideo: {vid_nr}/{n_vids}\\nTime : {in_seconds(timestamp)}/{int(watch_time)}\")\n",
    "    \n",
    "    # Sometimes the timestamp cannot be displayed\n",
    "    if timestamp:   \n",
    "        return in_seconds(timestamp) <= watch_time - 2\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipf(alpha, N):\n",
    "    \"\"\"Calculates Zipf distribution given variables\"\"\"\n",
    "    denominator = sum([1/n**alpha for n in range(1, N + 1)])\n",
    "    return [(1/k**alpha)/denominator for k in range(1, N + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    # Detect language\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except:\n",
    "        lang = \"en\"\n",
    "    # If the text is not in English, translate it, otherwise just return\n",
    "    if lang != \"en\":\n",
    "        #The translator only handles texts of less than 5000 characters, so we have to split the text\n",
    "        if len(text) >= 5000:\n",
    "            text_split = [text[start:start+4999] for start in range(0, len(text), 4999)]\n",
    "            try:\n",
    "                return ''.join([GoogleTranslator(source=\"auto\", target='en').translate(txt) for txt in text_split])\n",
    "            # Deal with connections stutters\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                # Wait three seconds to let the connection stablize\n",
    "                time.sleep(3)\n",
    "                # Try again, and if it still doesn't work, return the plain text\n",
    "                try:\n",
    "                    return ''.join([GoogleTranslator(source=\"auto\", target='en').translate(txt) for txt in text_split])\n",
    "                except:\n",
    "                    return text\n",
    "                \n",
    "        else:\n",
    "            # Deal with connection issues\n",
    "            try:\n",
    "                return GoogleTranslator(source=lang, target=\"en\").translate(text)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                time.sleep(3)\n",
    "                try:\n",
    "                    return GoogleTranslator(source=lang, target=\"en\").translate(text)\n",
    "                except:\n",
    "                    return text\n",
    "    \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    stripped = [word.strip(string.punctuation).lower() for word in word_tokenize(text) if word not in stop_words]\n",
    "    return \" \".join([stemmer.stem(word) for word in stripped if word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_conspiracy(recommendations, api, vectorizer, mlp, watched_videos):\n",
    "    \"\"\"Finds the most conspiracy-like video out of all recommendations\"\"\"\n",
    "    \n",
    "    print(\"Finding top conspiracy video...\")\n",
    "    \n",
    "    langs = (\"en\", \"nl\", \"af\", \"sq\", \"de\", \"am\", \"ar\",\"hy\",\"az\",\"eu\",\"be\",\"bn\",\"my\",\"bs\",\"bg\",\n",
    "             \"ca\",\"ceb\",\"zh-Hant\",\"zh-Hans\",\"co\",\"da\",\"en\",\"eo\",\"et\",\"fil\",\"fi\",\"fr\",\"fy\",\"gl\",\n",
    "             \"ka\",\"el\",\"gu\",\"ht\",\"ha\",\"haw\",\"iw\",\"hi\",\"hmn\",\"hu\",\"ga\",\"ig\",\"is\",\"id\",\"it\",\"ja\",\n",
    "             \"jv\",\"yi\",\"kn\",\"kk\",\"km\",\"rw\",\"ky\",\"ku\",\"ko\",\"hr\",\"lo\",\"la\",\"lv\",\"lt\",\"lb\",\"mk\",\"mg\",\n",
    "             \"ml\",\"ms\",\"mt\",\"mi\",\"mr\",\"mn\",\"ne\",\"no\",\"ny\",\"or\",\"ug\",\"uk\",\"uz\",\"ps\",\"fa\",\"pl\",\"pt\",\n",
    "             \"pa\",\"ro\",\"ru\",\"sm\",\"gd\",\"sr\",\"sn\",\"sd\",\"si\",\"sl\",\"sk\",\"su\",\"so\",\"es\",\"sw\",\"tg\",\"ta\",\n",
    "             \"tt\",\"te\",\"th\",\"cs\",\"tk\",\"tr\",\"ur\",\"vi\",\"cy\",\"xh\",\"yo\",\"zu\",\"st\",\"sv\")\n",
    "    rec_text = defaultdict(list)\n",
    "    indeces = []\n",
    "\n",
    "    # Get text for all recommendations\n",
    "    for i in recommendations:\n",
    "        # Find video id\n",
    "        try:\n",
    "            vid_id = i.split(\"?v=\")[1].split(\"&t=\")[0]\n",
    "        except:\n",
    "            continue\n",
    "        # Find title and description\n",
    "        try:\n",
    "            vid_dict = api.get_video_by_id(video_id = vid_id).items[0].to_dict()\n",
    "        except Exception as e:\n",
    "            if \"quota\" in str(e): # if the error was caused due to the quota-limit, refresh the key\n",
    "                api = update_key(api, keys)\n",
    "                vid_dict = api.get_video_by_id(video_id = vid_id).items[0].to_dict()\n",
    "                        \n",
    "        if vid_dict[\"snippet\"][\"title\"]:\n",
    "            title = vid_dict[\"snippet\"][\"title\"]\n",
    "        else:\n",
    "            title = \"\"\n",
    "        \n",
    "        if vid_dict[\"snippet\"][\"description\"]:\n",
    "            desc = vid_dict[\"snippet\"][\"description\"]\n",
    "        else:\n",
    "            desc = \"\"\n",
    "            \n",
    "        # Find channel keywords and description\n",
    "        try:\n",
    "            chnl = api.get_channel_info(channel_id=vid_dict[\"snippet\"][\"channelId\"]).items[0].to_dict()\n",
    "        except Exception as e:\n",
    "            if \"quota\" in str(e): # if the error was caused due to the quota-limit, refresh the key\n",
    "                api = update_key(api, keys)\n",
    "                chnl = api.get_channel_info(channel_id=vid_dict[\"snippet\"][\"channelId\"]).items[0].to_dict()\n",
    "        \n",
    "        if chnl[\"snippet\"][\"description\"]:\n",
    "            channel_desc = chnl[\"snippet\"][\"description\"]\n",
    "        else:\n",
    "            channel_desc = \"\"\n",
    "            \n",
    "        if chnl[\"brandingSettings\"][\"channel\"][\"keywords\"]:\n",
    "            channel_keywords = chnl[\"brandingSettings\"][\"channel\"][\"keywords\"]\n",
    "        else:\n",
    "            channel_keywords = \"\"\n",
    "            \n",
    "        try:\n",
    "            transcript = \" \".join([i[\"text\"] for i in YouTubeTranscriptApi.get_transcript(vid_id, languages=langs)])\n",
    "        except Exception as e:\n",
    "            transcript = \"\"\n",
    "        \n",
    "        indeces.append(vid_id)\n",
    "        rec_text[\"full_text\"].append(title + \" \" + desc + \" \" + transcript\\\n",
    "                                     + \" \" + channel_desc + \" \" + channel_keywords)\n",
    "        \n",
    "        rec_text[\"duration\"].append(vid_dict[\"contentDetails\"][\"duration\"])\n",
    "        \n",
    "    # Clean text\n",
    "    rec_text = pd.DataFrame(rec_text, index=indeces)\n",
    "    rec_text[\"full_text\"] = rec_text[\"full_text\"].apply(lambda txt: translate_text(txt))\n",
    "    rec_text[\"full_text\"] = rec_text[\"full_text\"].apply(lambda text: text.encode(\"ascii\", \"ignore\").decode())\n",
    "    rec_text[\"full_text\"] = rec_text[\"full_text\"].apply(lambda text: stem_text(text))    \n",
    "        \n",
    "    # Vectorize\n",
    "    tf_idf = vectorizer.transform(rec_text[\"full_text\"].values)\n",
    "    predictions = mlp.predict_proba(tf_idf)\n",
    "    \n",
    "    rec_text[\"non_con_odds\"] = predictions[:,0]\n",
    "    rec_text[\"con_odds\"] = predictions[:,1]\n",
    "        \n",
    "    # Most conspiracy-like video\n",
    "    top_conspiracy = rec_text.sort_values(by=\"con_odds\", ascending=False).iloc[0]\n",
    "    \n",
    "    # Get video id and length of the video\n",
    "    to_watch = top_conspiracy.name\n",
    "    \n",
    "    watched_ids = []\n",
    "    \n",
    "    for i in watched_videos:\n",
    "        try:\n",
    "            v_id = i.split(\"&t=\")[0].split(\"?v=\")[1]\n",
    "        except:\n",
    "            v_id = \"\"\n",
    "            \n",
    "        watched_ids.append(v_id)\n",
    "    \n",
    "    # Make sure the top conspiracy recommendation is a new video\n",
    "    i = 1\n",
    "    while to_watch in watched_ids:\n",
    "        # Most conspiracy-like video\n",
    "        top_conspiracy = rec_text.sort_values(by=\"con_odds\", ascending=False).iloc[i]\n",
    "        \n",
    "        # Get video id and length of the video\n",
    "        to_watch = top_conspiracy.name\n",
    "        \n",
    "        i += 1        \n",
    "    \n",
    "    vid_len = process_duration(top_conspiracy[\"duration\"])\n",
    "    \n",
    "    print(f\"Found top conspiracy video: {to_watch} ({top_conspiracy['con_odds']})\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    return vid_len, to_watch, api, top_conspiracy[\"con_odds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_recommendation(recommendations, api, vectorizer, mlp, watched_videos):\n",
    "    \"\"\"Selects a video to watch based on a top 20 of given recommendations\"\"\"\n",
    "    \n",
    "    # Find most likely conspiracy video\n",
    "    vid_len, to_watch, api, con_odds = get_top_conspiracy(recommendations, api, vectorizer, mlp, watched_videos)\n",
    "        \n",
    "    # If it most likely is not a conspiracy video, pick a recommendation\n",
    "    if con_odds < 0.25:       \n",
    "        # Choose a video according to the zipf-distribution of video-selection (Zhou et al., 2010)    \n",
    "        odds = zipf(0.78, len(recommendations))    \n",
    "        choice = np.random.choice(recommendations, p = odds)   \n",
    "\n",
    "        vid_len = pafy.new(choice).length\n",
    "\n",
    "        # Make sure no livestreams are clicked\n",
    "        while not vid_len or vid_len > 3600:\n",
    "            choice = np.random.choice(recommendations, p = odds)\n",
    "            vid_len = pafy.new(choice).length\n",
    "            to_watch = choice.replace(\"https://www.youtube.com/watch?v=\", \"\")\n",
    "        \n",
    "    # Calculate how much of the video will be watched\n",
    "    percentage = np.random.normal(0.55, 0.25)\n",
    "    \n",
    "    # Make sure a video is watched at most 100%\n",
    "    if percentage > 1:\n",
    "        percentage = 1\n",
    "    elif percentage < 0.1:\n",
    "        percentage = 0.1\n",
    "            \n",
    "    # Calculate how much of the video will be watched\n",
    "    watch_time = percentage * vid_len\n",
    "    \n",
    "    # Conspiracy videos might be longer than an hour\n",
    "    # So they should be watched at max 1 hour\n",
    "    if watch_time > 3600:\n",
    "        watch_time = 3600\n",
    "    \n",
    "    return watch_time, to_watch, api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Het experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def experiment_part_1(videos, vectorizer, vector, equal, user, api, n):\n",
    "    \"\"\"Watches YouTube videos on different YouTube accounts in different\n",
    "       ways. Videos are either retrieved from a dataset or chosen from the\n",
    "       recommendations. \n",
    "       \n",
    "       videos: the dataset containing videos (labeled as conspiracy True/False)\n",
    "       user: a dataset with YouTube-accounts (mail, password, usertype)\n",
    "       n: the number of videos to be watched during the experiment\n",
    "       \n",
    "       returns two dataframes: one containing the homepage recommendations after\n",
    "       each watched video, and one containing all the videos that have been watched.\"\"\" \n",
    "        \n",
    "    # Initialize variables\n",
    "    experiment_results = defaultdict(list)\n",
    "    videos_per_user = defaultdict(list)\n",
    "    crashes = defaultdict(list)\n",
    "    rec_to_watch = None\n",
    "\n",
    "    # Find current user's info\n",
    "    uid, mail, password, usertype = user[0], user[1], user[2], user[3]\n",
    "    \n",
    "    # Initialize driver\n",
    "    driver = init_driver()    \n",
    "\n",
    "    # Login to google\n",
    "    logged_in = login_google(driver, mail, password)\n",
    "    \n",
    "    # If login was successful, start watching videos\n",
    "    if logged_in:\n",
    "        # Start watching videos\n",
    "        for i in range(1, n + 1):\n",
    "            try:\n",
    "                # If the next video is not a recommendation (usertype 1 or 2)\n",
    "                if not rec_to_watch:\n",
    "                    # Get a random video from the dataset and watch it                \n",
    "                    watch_time, to_watch = vid_to_watch(videos, vectorizer, vector, equal, api, usertype = usertype,\n",
    "                                                        experiment_part = 1, user = uid, vid_num = i - 1)\n",
    "\n",
    "                    driver.get(f\"http://youtube.com/watch?v={to_watch}\")\n",
    "                    vid_running = True\n",
    "                else: # If it is one of the recommendations (usertype 3 or 4)\n",
    "                    # Watch the recommendation\n",
    "                    driver.get(f\"http://youtube.com/watch?v={rec_to_watch}\")\n",
    "                    vid_running = True\n",
    "\n",
    "                # Skip ads, disable autoplay\n",
    "                prepare_video(driver)\n",
    "\n",
    "                # Save information of current video being watched\n",
    "                videos_per_user[\"user\"].append(mail)\n",
    "                videos_per_user[\"video_number\"].append(i)\n",
    "                videos_per_user[\"url\"].append(driver.current_url)     \n",
    "\n",
    "                # Watch video\n",
    "                while check_video_running(driver, watch_time, i, n, uid):\n",
    "                    time.sleep(1)\n",
    "\n",
    "                # If we have a usertype that relies on direct recommendations\n",
    "                if usertype == 3 and i >= 5:\n",
    "                    try:\n",
    "                        driver.find_element_by_xpath(\"//button[contains(@class, 'ytp-play-button')]\").click()\n",
    "                    except:\n",
    "                        pass\n",
    "                    video_recs = driver.find_elements_by_xpath(\n",
    "                        \"//a[contains(@class, 'ytd-compact-video-renderer')]\")                    \n",
    "                    watch_time, rec_to_watch, api = choose_recommendation([rec.get_attribute(\"href\")\n",
    "                                                                           for rec in video_recs][:20], \n",
    "                                                                           api, vectorizer, mlp,\n",
    "                                                                           videos_per_user[\"url\"])\n",
    "                    \n",
    "\n",
    "                # Go to the youtube homepage\n",
    "                driver.get(\"http://youtube.com\")\n",
    "                time.sleep(1.5)\n",
    "\n",
    "                # Get videos on youtube home\n",
    "                channels = driver.find_elements_by_xpath(\"//a[@id = 'avatar-link']\")\n",
    "                vids = driver.find_elements_by_xpath(\"//a[@id = 'video-title-link']\")\n",
    "\n",
    "                # If we have a user that relies on homepage recommendations\n",
    "                if usertype == 4 and i >= 5:\n",
    "                    watch_time, rec_to_watch, api = choose_recommendation([rec.get_attribute(\"href\")\n",
    "                                                                           for rec in vids][:20],\n",
    "                                                                           api, vectorizer, mlp,\n",
    "                                                                           videos_per_user[\"url\"])\n",
    "\n",
    "                # Get top 20 recommendations\n",
    "                for rec in range(20):\n",
    "                    experiment_results[\"user\"].append(mail)\n",
    "                    experiment_results[\"vids_watched\"].append(i)\n",
    "\n",
    "                    experiment_results[\"video\"].append(vids[rec].get_attribute(\"href\"))\n",
    "                    experiment_results[\"channel\"].append(channels[rec].get_attribute(\"href\"))\n",
    "\n",
    "            except Exception as e: # if the video somehow doesn't get watched\n",
    "                # Store where the crash happened and why\n",
    "                crashes[\"user\"].append(user[0])\n",
    "                crashes[\"video number\"].append(i)\n",
    "                crashes[\"reason\"].append(repr(e))\n",
    "    else:\n",
    "        driver.quit()\n",
    "        return None, None, None\n",
    "            \n",
    "    driver.quit()\n",
    "    return experiment_results, videos_per_user, crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 0\n",
      "Video: 15/15\n",
      "Time : 18/19\n",
      "Finding top conspiracy video...\n",
      "Found top conspiracy video: GVM6Nhewxek (0.9998443057003733)\n",
      "Script executed without errors!\n"
     ]
    }
   ],
   "source": [
    "logs_1 = pd.DataFrame(columns=[\"user\", \"video number\", \"reason\"])\n",
    "failures = []\n",
    "\n",
    "# Go over every user in the csv\n",
    "for user in mails.itertuples():\n",
    "    if user[0] == 0:\n",
    "        # Run experiment part 1 for current user\n",
    "        recommendations, watched_videos, crashes = experiment_part_1(videos, vectorizer, vector, equal, user, api, 15)\n",
    "\n",
    "        if recommendations is not None:\n",
    "            # Save results for current user\n",
    "            try:\n",
    "                recommendations = pd.DataFrame(recommendations)\n",
    "                recommendations.to_csv(f\"recommendations_user_{user[0]}.csv\")\n",
    "            except:\n",
    "                failures.append(f\"recommendations_user_{user[0]}.csv\")\n",
    "\n",
    "            try:\n",
    "                watched_videos = pd.DataFrame(watched_videos)\n",
    "                watched_videos.to_csv(f\"watched_videos_user_{user[0]}.csv\")\n",
    "            except:\n",
    "                failures.append(f\"watched_videos_user_{user[0]}.csv\")\n",
    "\n",
    "        if crashes:\n",
    "            logs_1 = pd.concat([logs_1, pd.DataFrame(crashes)], ignore_index=True)\n",
    "                \n",
    "if len(logs_1):\n",
    "    logs_1.to_csv(\"logs_experiment_1.csv\")\n",
    "if failures:\n",
    "    print(failures)\n",
    "else:\n",
    "    print(\"Script executed without errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_part_2(videos, user, n):\n",
    "    \"\"\"Watches non-conspiracy videos on accounts in filter bubbles to see\n",
    "       how quickly they can escape the bubble. \n",
    "   \n",
    "       videos: the dataset containing videos (labeled as conspiracy True/False)\n",
    "       user: a dataset with YouTube-accounts (mail, password, usertype)\n",
    "       n: the number of videos to be watched during the experiment\n",
    "       \n",
    "       returns two dataframes: one containing the homepage recommendations after\n",
    "       each watched video, and one containing all the videos that have been watched.\"\"\" \n",
    "    \n",
    "    # Initialize variables\n",
    "    experiment_2_results = defaultdict(list)\n",
    "    videos_per_user_2 = defaultdict(list)\n",
    "    crashes_2 = defaultdict(list)\n",
    "\n",
    "    # Find current user's info\n",
    "    uid, mail, password = user[0], user[1], user[2]\n",
    "    \n",
    "    # Initialize driver\n",
    "    driver = init_driver()    \n",
    "\n",
    "    # Login to google\n",
    "    login_google(driver, mail, password)\n",
    "    \n",
    "    # Start watching videos\n",
    "    for i in range(1, n + 1):\n",
    "        try:\n",
    "            # Get a random video from the dataset and watch it\n",
    "            watch_time, to_watch = vid_to_watch(videos, usertype, experiment_part = 2)\n",
    "            driver.get(f\"http://youtube.com/watch?v={to_watch}\")\n",
    "            vid_running = True\n",
    "\n",
    "            # Skip ads, disable autoplay\n",
    "            prepare_video(driver)\n",
    "\n",
    "            # Save information of current video being watched\n",
    "            views, likes, dislikes, date, url = get_video_info(driver)\n",
    "\n",
    "            videos_per_user_2[\"user\"].append(mail)\n",
    "            videos_per_user_2[\"video_number\"].append(i)\n",
    "            videos_per_user_2[\"url\"].append(url)\n",
    "            videos_per_user_2[\"views\"].append(views)\n",
    "            videos_per_user_2[\"likes\"].append(likes)\n",
    "            videos_per_user_2[\"dislikes\"].append(dislikes)\n",
    "            videos_per_user_2[\"date\"].append(date)         \n",
    "            \n",
    "            # Watch video\n",
    "            while check_video_running(driver, watch_time, i, n, uid):\n",
    "                time.sleep(1)\n",
    "\n",
    "            # Go to the youtube homepage\n",
    "            driver.get(\"http://youtube.com\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            # Get videos on youtube home\n",
    "            channels = driver.find_elements_by_xpath(\"//a[@id = 'avatar-link']\")\n",
    "            vids = driver.find_elements_by_xpath(\"//a[@id = 'video-title-link']\")\n",
    "\n",
    "            # Get top 20 recommendations\n",
    "            for rec in range(20):\n",
    "                experiment_2_results[\"user\"].append(mail)\n",
    "                experiment_2_results[\"vids_watched\"].append(i)\n",
    "\n",
    "                experiment_2_results[\"video\"].append(vids[rec].get_attribute(\"href\"))\n",
    "                experiment_2_results[\"channel\"].append(channels[rec].get_attribute(\"href\"))\n",
    "                \n",
    "        except Exception as e: # if the video somehow doesn't get watched\n",
    "            # Store where the crash happened and why\n",
    "            crashes_2[\"user\"].append(user[0])\n",
    "            crashes_2[\"video number\"].append(i)\n",
    "            crashes_2[\"reason\"].append(repr(e))\n",
    "            \n",
    "    driver.quit()         \n",
    "    return pd.DataFrame(experiment_2_results), pd.DataFrame(videos_per_user_2), pd.DataFrame(crashes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_2 = pd.DataFrame(columns=[\"user\", \"video number\", \"reason\"])\n",
    "\n",
    "# Go over every user in the csv\n",
    "for user in notebook.tqdm(mails.itertuples()):\n",
    "    # Run experiment part 2\n",
    "    recommendations_2, watched_videos_2, crashes_2 = experiment_part_2(videos, user, 15)\n",
    "            \n",
    "    # Store the results\n",
    "    recommendations_2.to_csv(f\"recommendations_part_2_user_{user[0]}.csv\")\n",
    "    watched_videos_2.to_csv(f\"watched_videos_part_2_user_{user[0]}.csv\")\n",
    "    \n",
    "    if len(crashes):\n",
    "        logs_2 = pd.concat([logs_2, crashes], ignore_index=True)\n",
    "    \n",
    "    break\n",
    "    \n",
    "if len(logs_2):\n",
    "    logs_2.to_csv(\"logs_experiment_2.csv\")\n",
    "else:\n",
    "    print(\"Script executed without errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
